{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherTransformer(nn.Module):\n",
    "    def __init__(self, feature_size, num_layers=1, num_decoders=5):\n",
    "        super(WeatherTransformer, self).__init__()\n",
    "        self.num_decoders = num_decoders\n",
    "\n",
    "        encoder_layers = TransformerEncoderLayer(d_model=feature_size, nhead=5)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers)\n",
    "\n",
    "        self.decoders = nn.ModuleList([\n",
    "            TransformerDecoder(TransformerDecoderLayer(d_model=feature_size, nhead=5), num_layers)\n",
    "            for _ in range(num_decoders)\n",
    "        ])\n",
    "    \n",
    "    def forward(self, src):\n",
    "        memory = self.transformer_encoder(src)\n",
    "        outputs = []\n",
    "        for decoder in self.decoders:\n",
    "            output = decoder(memory, memory)\n",
    "            outputs.append(output)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_data(files):\n",
    "    data = [pd.read_excel(file) for file in files]\n",
    "    return data\n",
    "\n",
    "def prepare_data(data, labels=True):\n",
    "    if labels:\n",
    "\n",
    "        features = [torch.tensor(d.iloc[:, 1:].values, dtype=torch.float32) for d in data]\n",
    "        targets = [torch.tensor(d.iloc[:, 0].values, dtype=torch.float32).view(-1, 1) for d in data]\n",
    "        return features, targets\n",
    "    else:\n",
    "        features = [torch.tensor(d.values, dtype=torch.float32) for d in data]\n",
    "        return features\n",
    "    \n",
    "\n",
    "def train_model(model, train_loader, num_epochs=2):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        for features, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(features)\n",
    "            loss = sum([criterion(output.squeeze(), target) for output, target in zip(outputs, targets)])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}')\n",
    "\n",
    "\n",
    "def predict(model, test_data):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_data:\n",
    "            output = model(data.unsqueeze(0)) \n",
    "            predictions.append(output)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_files = ['train_1.xlsx', 'train_2.xlsx', 'train_3.xlsx',\n",
    "                   ]\n",
    "    test_files = ['test_1.xlsx', 'test_2.xlsx', 'test_3.xlsx',\n",
    "                  ]\n",
    "\n",
    "\n",
    "    train_data = load_data(train_files)\n",
    "    train_features, train_targets = prepare_data(train_data)\n",
    "    train_dataset = TensorDataset(torch.cat(train_features, dim=0), torch.cat(train_targets, dim=0))\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "    feature_size = 5 \n",
    "    model = WeatherTransformer(feature_size)\n",
    "\n",
    "\n",
    "    train_model(model, train_loader)\n",
    "\n",
    "    test_data = load_data(test_files)\n",
    "    test_features = prepare_data(test_data, labels=False)\n",
    "\n",
    "\n",
    "    predictions = predict(model, test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_predictions = pd.DataFrame()\n",
    "\n",
    "\n",
    "for idx, pred in enumerate(predictions):\n",
    "    pred_df = pd.DataFrame(pred[0].squeeze().numpy())\n",
    "    pred_df.columns = [f'prediction_wind_farm_{idx+1}_col_{i+1}' for i in range(pred_df.shape[1])] \n",
    "    if all_predictions.empty:\n",
    "        all_predictions = pred_df\n",
    "    else:\n",
    "        all_predictions = pd.concat([all_predictions, pred_df], axis=1)\n",
    "\n",
    "\n",
    "all_predictions.to_csv('all_predictions.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
